{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from deepface import dataloader, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FER Dataset (Train / Dev / Test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = dataloader.train_dev_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 28709\n",
      "Dev set size: 3589\n",
      "Test set size: 3589\n",
      "\n",
      "Image shape: (48, 48, 1)\n",
      "Number of classes: 7\n",
      "Classes: ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set size: {len(train[0])}')\n",
    "print(f'Dev set size: {len(dev[0])}')\n",
    "print(f'Test set size: {len(test[0])}')\n",
    "print()\n",
    "\n",
    "print(f'Image shape: {dataloader.IMG_SHAPE}')\n",
    "print(f'Number of classes: {len(dataloader.LABELS_MAP.values())}')\n",
    "print(f'Classes: {list(dataloader.LABELS_MAP.values())}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(h, w, in_C, n_classes):\n",
    "    with tf.name_scope('placeholders'):\n",
    "        X = tf.placeholder(tf.float32, shape=[None, h, w, in_C], name='X')\n",
    "        Y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X):\n",
    "    # Conv2d: 8 filters, 7x7, strides=1, padding='SAME':\n",
    "    X = layers.conv2d(X, n_filters=8, size=[7, 7], strides=[1, 1, 1, 1], padding='VALID', name='conv2d-layer-1')\n",
    "    \n",
    "    # MaxPool: 2x2, strides=1, padding='VALID'\n",
    "    X = layers.maxpool(X, size=[2, 2], strides=[1, 1, 1, 1], padding='VALID', name='maxpool-layer-1')\n",
    "    \n",
    "    # ReLU\n",
    "    X = tf.nn.relu(X, name='relu-layer-1')\n",
    "    \n",
    "    # Conv2d: 16 filters, 9x9, strides=1, padding='VALID':\n",
    "    X = layers.conv2d(X, n_filters=16, size=[9, 9], strides=[1, 1, 1, 1], padding='VALID', name='conv2d-layer-2')\n",
    "    \n",
    "    # MaxPool: 2x2, strides=1, padding='VALID'\n",
    "    X = layers.maxpool(X, size=[2, 2], strides=[1, 1, 1, 1], padding='VALID', name='maxpool-layer-2')\n",
    "    \n",
    "    # ReLU\n",
    "    X = tf.nn.relu(X, name='relu-layer-1')\n",
    "    \n",
    "    # Flatten\n",
    "    X = tf.layers.flatten(X, name='flatten')\n",
    "    \n",
    "    # FC 1\n",
    "    X = layers.fully_connected(X, units=20, activation=tf.nn.sigmoid, name='fc-layer-1')\n",
    "    \n",
    "    # FC 2\n",
    "    Z = layers.fully_connected(X, units=7, activation=None, name='fc-layers-2')\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y, Z):\n",
    "    return tf.reduce_mean(\n",
    "        tf.losses.softmax_cross_entropy(onehot_labels=Y, logits=Z)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train, dev, test, lr=1e-3, batch_size=32, num_epochs=5, run=1):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    m, h, w, in_C = train[0].shape\n",
    "    _, n_classes = train[1].shape\n",
    "    num_batches_per_epoch = m // batch_size\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        # Placeholders\n",
    "        X, Y = create_placeholders(h, w, in_C, n_classes)\n",
    "\n",
    "        # Forward-propagation\n",
    "        Z = forward_prop(X)\n",
    "\n",
    "        # Cost\n",
    "        with tf.name_scope('xent'):\n",
    "            cost = compute_cost(Y, Z)\n",
    "            tf.summary.scalar('xent', cost)\n",
    "\n",
    "        # Optimizer\n",
    "        with tf.name_scope('optimizer'):\n",
    "            optimize = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "        # Prepare training data\n",
    "        with tf.name_scope('train_dataset'):\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices(train)\n",
    "            train_dataset = train_dataset.repeat(num_epochs).shuffle(m*num_epochs).batch(batch_size)\n",
    "\n",
    "            next_minibatch = train_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope('accuracy'):\n",
    "            predict_op = tf.argmax(Z, 1)\n",
    "            correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        summaries = tf.summary.merge_all()\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "            k = 0\n",
    "            epoch = 1\n",
    "            epoch_cost = 0.\n",
    "            epoch_acc = 0.\n",
    "            writer = tf.summary.FileWriter('./boards/'+str(run))\n",
    "            writer.add_graph(tf.get_default_graph())\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    minibatch_X, minibatch_Y = sess.run(next_minibatch)\n",
    "                    (_, tmp_cost, tmp_acc, s) = sess.run(\n",
    "                        (optimize, cost, accuracy, summaries),\n",
    "                        feed_dict={\n",
    "                            X: minibatch_X,\n",
    "                            Y: minibatch_Y\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    epoch_cost += tmp_cost / num_batches_per_epoch\n",
    "                    epoch_acc += tmp_acc / num_batches_per_epoch\n",
    "\n",
    "                    k+=1\n",
    "                    writer.add_summary(s, k)\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "                if k % num_batches_per_epoch == 0:\n",
    "                    print(f'EPOCH {epoch}   |||   COST: {epoch_cost}   |||   Acurracy: {epoch_acc}')                \n",
    "                    epoch += 1\n",
    "                    epoch_cost = 0.\n",
    "                    epoch_acc = 0.\n",
    "\n",
    "            train_accuracy = accuracy.eval({X: train[0], Y: train[1]})\n",
    "            dev_accuracy = accuracy.eval({X: dev[0], Y: dev[1]})\n",
    "            print('Train Accuracy:', train_accuracy)\n",
    "            print('Dev Accuracy:', dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1   |||   COST: 2.5617077387827822   |||   Acurracy: 0.13872630992196278\n",
      "EPOCH 2   |||   COST: 2.425710252561966   |||   Acurracy: 0.13959726867335645\n",
      "Train Accuracy: 0.13915497\n",
      "Dev Accuracy: 0.1368069\n"
     ]
    }
   ],
   "source": [
    "model(train, dev, test, lr=1e-5, batch_size=32, num_epochs=2, run=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
