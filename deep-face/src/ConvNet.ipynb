{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import dataloader\n",
    "import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FER Dataset (Train / Dev / Test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = dataloader.train_dev_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 28709\n",
      "Dev set size: 3589\n",
      "Test set size: 3589\n",
      "\n",
      "Image shape: (48, 48, 1)\n",
      "Number of classes: 7\n",
      "Classes: ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set size: {len(train[0])}')\n",
    "print(f'Dev set size: {len(dev[0])}')\n",
    "print(f'Test set size: {len(test[0])}')\n",
    "print()\n",
    "\n",
    "print(f'Image shape: {dataloader.IMG_SHAPE}')\n",
    "print(f'Number of classes: {len(dataloader.LABELS_MAP.values())}')\n",
    "print(f'Classes: {list(dataloader.LABELS_MAP.values())}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(h, w, in_C, n_classes):\n",
    "    with tf.name_scope('placeholders'):\n",
    "        X = tf.placeholder(tf.float32, shape=[None, h, w, in_C], name='X')\n",
    "        Y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X):\n",
    "    # Conv2d: 8 filters, 7x7, strides=1, padding='SAME':\n",
    "    X = layers.conv2d(X, n_filters=8, size=[7, 7], strides=[1, 1, 1, 1], padding='VALID', name='conv2d-layer-1')\n",
    "    \n",
    "    # MaxPool: 2x2, strides=1, padding='VALID'\n",
    "    X = layers.maxpool(X, size=[2, 2], strides=[1, 1, 1, 1], padding='VALID', name='maxpool-layer-1')\n",
    "    \n",
    "    # ReLU\n",
    "    X = tf.nn.relu(X, name='relu-layer-1')\n",
    "    \n",
    "    # Conv2d: 16 filters, 9x9, strides=1, padding='VALID':\n",
    "    X = layers.conv2d(X, n_filters=16, size=[9, 9], strides=[1, 1, 1, 1], padding='VALID', name='conv2d-layer-2')\n",
    "    \n",
    "    # MaxPool: 2x2, strides=1, padding='VALID'\n",
    "    X = layers.maxpool(X, size=[2, 2], strides=[1, 1, 1, 1], padding='VALID', name='maxpool-layer-2')\n",
    "    \n",
    "    # ReLU\n",
    "    X = tf.nn.relu(X, name='relu-layer-1')\n",
    "    \n",
    "    # Flatten\n",
    "    X = tf.layers.flatten(X, name='flatten')\n",
    "    \n",
    "    # FC 1\n",
    "    X = layers.fully_connected(X, units=20, activation=tf.nn.sigmoid, name='fc-layer-1')\n",
    "    \n",
    "    # FC 2\n",
    "    Z = layers.fully_connected(X, units=7, activation=None, name='fc-layers-2')\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y, Z):\n",
    "    return tf.reduce_mean(\n",
    "        tf.losses.softmax_cross_entropy(onehot_labels=Y, logits=Z)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train, dev, test, lr=1e-3, batch_size=32, num_epochs=5, run=1):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    m, h, w, in_C = train[0].shape\n",
    "    _, n_classes = train[1].shape\n",
    "    num_batches_per_epoch = m // batch_size\n",
    "    \n",
    "    # Placeholders\n",
    "    X, Y = create_placeholders(h, w, in_C, n_classes)\n",
    "    \n",
    "    # Forward-propagation\n",
    "    Z = forward_prop(X)\n",
    "    \n",
    "    # Cost\n",
    "    with tf.name_scope('xent'):\n",
    "        cost = compute_cost(Y, Z)\n",
    "        tf.summary.scalar('xent', cost)\n",
    "        \n",
    "    # Optimizer\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimize = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "        \n",
    "    # Prepare training data\n",
    "    with tf.name_scope('train_dataset'):\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train)\n",
    "        train_dataset = train_dataset.repeat(num_epochs).shuffle(m*num_epochs).batch(batch_size)\n",
    "\n",
    "        next_minibatch = train_dataset.make_one_shot_iterator().get_next()\n",
    "        \n",
    "    # Accuracy\n",
    "    with tf.name_scope('accuracy'):\n",
    "        predict_op = tf.argmax(Z, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        \n",
    "    summaries = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        k = 0\n",
    "        epoch = 1\n",
    "        epoch_cost = 0.\n",
    "        epoch_acc = 0.\n",
    "        writer = tf.summary.FileWriter('./boards/'+str(run))\n",
    "        writer.add_graph(sess.graph)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                minibatch_X, minibatch_Y = sess.run(next_minibatch)\n",
    "                (_, tmp_cost, tmp_acc, s) = sess.run(\n",
    "                    (optimize, cost, accuracy, summaries),\n",
    "                    feed_dict={\n",
    "                        X: minibatch_X,\n",
    "                        Y: minibatch_Y\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                epoch_cost += tmp_cost / num_batches_per_epoch\n",
    "                epoch_acc += tmp_acc / num_batches_per_epoch\n",
    "            \n",
    "                k+=1\n",
    "                writer.add_summary(s, k)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "            \n",
    "            if k % num_batches_per_epoch == 0:\n",
    "                print(f'EPOCH {epoch}   |||   COST: {epoch_cost}   |||   Acurracy: {epoch_acc}')                \n",
    "                epoch += 1\n",
    "                epoch_cost = 0.\n",
    "                epoch_acc = 0.\n",
    "\n",
    "        train_accuracy = accuracy.eval({X: train[0], Y: train[1]})\n",
    "        dev_accuracy = accuracy.eval({X: dev[0], Y: dev[1]})\n",
    "        print('Train Accuracy:', train_accuracy)\n",
    "        print('Dev Accuracy:', dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1   |||   COST: 1.9918139738382699   |||   Acurracy: 0.23784141583054594\n",
      "EPOCH 2   |||   COST: 1.9239444868221718   |||   Acurracy: 0.2591973244147154\n",
      "EPOCH 3   |||   COST: 1.8947951328528494   |||   Acurracy: 0.2654333890746935\n",
      "EPOCH 4   |||   COST: 1.8681356365997006   |||   Acurracy: 0.2826435340022302\n",
      "EPOCH 5   |||   COST: 1.8304020699317118   |||   Acurracy: 0.3040691192865118\n",
      "EPOCH 6   |||   COST: 1.813671268082515   |||   Acurracy: 0.30831939799331226\n",
      "EPOCH 7   |||   COST: 1.7835974795629626   |||   Acurracy: 0.3224986064659996\n",
      "EPOCH 8   |||   COST: 1.7683098641792134   |||   Acurracy: 0.33329849498327924\n",
      "EPOCH 9   |||   COST: 1.748855076771784   |||   Acurracy: 0.33761845039019117\n",
      "EPOCH 10   |||   COST: 1.7283334401140236   |||   Acurracy: 0.33848940914158504\n",
      "Train Accuracy: 0.34637222\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f13cf0535766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5a696fa825d9>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(train, dev, test, lr, batch_size, num_epochs, run)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mdev_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dev Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "model(train, dev, test, lr=1e-5, batch_size=32, num_epochs=10, run=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
